{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Page to be crawled: https://w3schools.com\n",
      "===================\n",
      "https://www.w3schools.com\n",
      "javascript:void(0)\n",
      "https://w3schools.com/html/default.asp\n",
      "https://w3schools.com/css/default.asp\n",
      "https://w3schools.com/bootstrap/bootstrap_ver.asp\n",
      "https://w3schools.com/w3css/default.asp\n",
      "https://w3schools.com/colors/default.asp\n",
      "https://w3schools.com/icons/default.asp\n",
      "https://w3schools.com/graphics/default.asp\n",
      "https://w3schools.com/howto/default.asp\n",
      "https://w3schools.com/sass/default.asp\n",
      "https://w3schools.com/js/default.asp\n",
      "https://w3schools.com/jquery/default.asp\n",
      "https://w3schools.com/react/default.asp\n",
      "https://w3schools.com/angular/default.asp\n",
      "https://w3schools.com/js/js_json_intro.asp\n",
      "https://w3schools.com/js/js_ajax_intro.asp\n",
      "https://w3schools.com/w3js/default.asp\n",
      "https://w3schools.com/sql/default.asp\n",
      "https://w3schools.com/php/default.asp\n",
      "https://w3schools.com/asp/default.asp\n",
      "https://w3schools.com/nodejs/default.asp\n",
      "https://w3schools.com/nodejs/nodejs_raspberrypi.asp\n",
      "https://w3schools.com/python/default.asp\n",
      "https://w3schools.com/java/default.asp\n",
      "https://w3schools.com/cpp/default.asp\n",
      "https://w3schools.com/w3css/w3css_templates.asp\n",
      "https://w3schools.com/browsers/default.asp\n",
      "https://w3schools.com/cert/default.asp\n",
      "https://w3schools.com/tryit/default.asp\n",
      "https://w3schools.com/whatis/default.asp\n",
      "https://w3schools.com/xml/default.asp\n",
      "https://w3schools.com/xml/ajax_intro.asp\n",
      "https://w3schools.com/xml/dom_intro.asp\n",
      "https://w3schools.com/xml/xml_dtd_intro.asp\n",
      "https://w3schools.com/xml/schema_intro.asp\n",
      "https://w3schools.com/xml/xsl_intro.asp\n",
      "https://w3schools.com/xml/xpath_intro.asp\n",
      "https://w3schools.com/xml/xquery_intro.asp\n",
      "https://w3schools.com/tags/default.asp\n",
      "https://w3schools.com/cssref/default.asp\n",
      "https://w3schools.com/jsref/default.asp\n",
      "https://w3schools.com/sql/sql_ref_keywords.asp\n",
      "https://w3schools.com/php/php_ref_overview.asp\n",
      "https://w3schools.com/jquery/jquery_ref_overview.asp\n",
      "https://w3schools.com/python/python_reference.asp\n",
      "https://w3schools.com/bootstrap/bootstrap_ref_all_classes.asp\n",
      "https://w3schools.com/bootstrap4/bootstrap_ref_all_classes.asp\n",
      "https://w3schools.com/w3css/w3css_references.asp\n",
      "https://w3schools.com/java/java_ref_keywords.asp\n",
      "https://w3schools.com/angular/angular_ref_directives.asp\n",
      "https://w3schools.com/sass/sass_functions_string.asp\n",
      "https://w3schools.com/charsets/default.asp\n",
      "https://w3schools.com/html/html_exercises.asp\n",
      "https://w3schools.com/css/css_exercises.asp\n",
      "https://w3schools.com/js/js_exercises.asp\n",
      "https://w3schools.com/sql/sql_exercises.asp\n",
      "https://w3schools.com/php/php_exercises.asp\n",
      "https://w3schools.com/python/python_exercises.asp\n",
      "https://w3schools.com/java/java_exercises.asp\n",
      "https://w3schools.com/cpp/cpp_exercises.asp\n",
      "https://w3schools.com/bootstrap/bootstrap_exercises.asp\n",
      "javascript:void(0);\n",
      "https://w3schools.com/graphics/svg_intro.asp\n",
      "https://w3schools.com/graphics/canvas_intro.asp\n",
      "https://w3schools.com/tags/ref_eventattributes.asp\n",
      "https://w3schools.com/tags/ref_attributes.asp\n",
      "https://w3schools.com/tags/ref_canvas.asp\n",
      "https://w3schools.com/graphics/svg_reference.asp\n",
      "https://w3schools.com/graphics/google_maps_reference.asp\n",
      "https://w3schools.com/cssref/css3_browsersupport.asp\n",
      "https://w3schools.com/cssref/css_selectors.asp\n",
      "https://w3schools.com/icons/icons_reference.asp\n",
      "https://w3schools.com/w3js/w3js_references.asp\n",
      "https://w3schools.com/asp/asp_ref_response.asp\n",
      "https://w3schools.com/xml/dom_nodetype.asp\n",
      "https://w3schools.com/xml/dom_http.asp\n",
      "https://w3schools.com/xml/xsl_elementref.asp\n",
      "https://w3schools.com/xml/schema_elements_ref.asp\n",
      "https://w3schools.com/charsets/ref_html_ascii.asp\n",
      "https://w3schools.com/charsets/ref_html_ansi.asp\n",
      "https://w3schools.com/charsets/ref_html_8859.asp\n",
      "https://w3schools.com/charsets/ref_html_symbols.asp\n",
      "https://w3schools.com/charsets/ref_html_utf8.asp\n",
      "https://w3schools.com/html/html_examples.asp\n",
      "https://w3schools.com/css/css_examples.asp\n",
      "https://w3schools.com/w3css/w3css_examples.asp\n",
      "https://w3schools.com/bootstrap/bootstrap_examples.asp\n",
      "https://w3schools.com/graphics/svg_examples.asp\n",
      "https://w3schools.com/html/html_quiz.asp\n",
      "https://w3schools.com/css/css_quiz.asp\n",
      "https://w3schools.com/js/js_quiz.asp\n",
      "https://w3schools.com/sql/sql_quiz.asp\n",
      "https://w3schools.com/php/php_quiz.asp\n",
      "https://w3schools.com/python/python_quiz.asp\n",
      "https://w3schools.com/bootstrap/bootstrap_quiz.asp\n",
      "https://w3schools.com/jquery/jquery_quiz.asp\n",
      "https://w3schools.com/xml/xml_quiz.asp\n",
      "https://w3schools.com/js/js_examples.asp\n",
      "https://w3schools.com/js/js_dom_examples.asp\n",
      "==============\n",
      "Pages crawled:\n",
      "==============\n",
      "visited 1\n",
      "https://w3schools.com\n"
     ]
    }
   ],
   "source": [
    "#BF Crawler\n",
    "from collections import deque\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "#import sys\n",
    "import urllib\n",
    "\n",
    "# Read URL from command line\n",
    "url = 'https://w3schools.com'\n",
    "#sys.argv[1]\n",
    "\n",
    "print(\"===================\")\n",
    "print(\"Page to be crawled:\", url)\n",
    "print(\"===================\")\n",
    "\n",
    "\n",
    "# Create queue\n",
    "queue = deque([])\n",
    "\n",
    "# Maintains list of visited pages\n",
    "visited_list = []\n",
    "\n",
    "\n",
    "# Crawl the page and populate the queue with newly found URLs\n",
    "def crawl(url):\n",
    "    visited_list.append(url)\n",
    "    if len(queue) > 99:\n",
    "        return\n",
    "\n",
    "    urlf = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(urlf.read())\n",
    "    urls = soup.findAll(\"a\", href=True)\n",
    "\n",
    "    for i in urls:\n",
    "        flag = 0\n",
    "        # Complete relative URLs and strip trailing slash\n",
    "        complete_url = urljoin(url, i[\"href\"]).rstrip('/')\n",
    "\n",
    "        # Check if the URL already exists in the queue\n",
    "        for j in queue:\n",
    "            if j == complete_url:\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "        # If not found in queue\n",
    "        if flag == 0:\n",
    "            if len(queue) > 99:\n",
    "                return\n",
    "            if (visited_list.count(complete_url)) == 0:\n",
    "                queue.append(complete_url)\n",
    "\n",
    "    # Pop one URL from the queue from the left side so that it can be crawled\n",
    "    current = queue.popleft()\n",
    "    # Recursive call to crawl until the queue is populated with 100 URLs\n",
    "    crawl(current)\n",
    "\n",
    "crawl(url)\n",
    "\n",
    "# Print queue\n",
    "for i in queue:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "print( \"==============\")\n",
    "print( \"Pages crawled:\")\n",
    "print( \"==============\")\n",
    "\n",
    "\n",
    "# Print list of visited pages\n",
    "count=0\n",
    "for i in visited_list:\n",
    "    count+=1\n",
    "    print('visited',end=' ')\n",
    "    print(count)\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use formulas and not functions for tfidf and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser  \n",
    "from urllib.request import urlopen  \n",
    "from urllib import parse\n",
    "\n",
    "# We are going to create a class called LinkParser that inherits some\n",
    "# methods from HTMLParser which is why it is passed into the definition\n",
    "class LinkParser(HTMLParser):\n",
    "\n",
    "    # This is a function that HTMLParser normally has\n",
    "    # but we are adding some functionality to it\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        # We are looking for the begining of a link. Links normally look\n",
    "        # like <a href=\"www.someurl.com\"></a>\n",
    "        if tag == 'a':\n",
    "            for (key, value) in attrs:\n",
    "                if key == 'href':\n",
    "                    # We are grabbing the new URL. We are also adding the\n",
    "                    # base URL to it. For example:\n",
    "                    # www.netinstructions.com is the base and\n",
    "                    # somepage.html is the new URL (a relative URL)\n",
    "                    #\n",
    "                    # We combine a relative URL with the base URL to create\n",
    "                    # an absolute URL like:\n",
    "                    # www.netinstructions.com/somepage.html\n",
    "                    newUrl = parse.urljoin(self.baseUrl, value)\n",
    "                    # And add it to our colection of links:\n",
    "                    self.links = self.links + [newUrl]\n",
    "\n",
    "    # This is a new function that we are creating to get links\n",
    "    # that our spider() function will call\n",
    "    def getLinks(self, url):\n",
    "        self.links = []\n",
    "        # Remember the base URL which will be important when creating\n",
    "        # absolute URLs\n",
    "        self.baseUrl = url\n",
    "        # Use the urlopen function from the standard Python 3 library\n",
    "        response = urlopen(url)\n",
    "        # Make sure that we are looking at HTML and not other things that\n",
    "        # are floating around on the internet (such as\n",
    "        # JavaScript files, CSS, or .PDFs for example)\n",
    "        if response.getheader('Content-Type')=='text/html':\n",
    "            htmlBytes = response.read()\n",
    "            # Note that feed() handles Strings well, but not bytes\n",
    "            # (A change from Python 2.x to Python 3.x)\n",
    "            htmlString = htmlBytes.decode(\"utf-8\")\n",
    "            self.feed(htmlString)\n",
    "            return htmlString, self.links\n",
    "        else:\n",
    "            return \"\",[]\n",
    "\n",
    "# And finally here is our spider. It takes in an URL, a word to find,\n",
    "# and the number of pages to search through before giving up\n",
    "def spider(url, word, maxPages):  \n",
    "    pagesToVisit = [url]\n",
    "    numberVisited = 0\n",
    "    foundWord = False\n",
    "    # The main loop. Create a LinkParser and get all the links on the page.\n",
    "    # Also search the page for the word or string\n",
    "    # In our getLinks function we return the web page\n",
    "    # (this is useful for searching for the word)\n",
    "    # and we return a set of links from that web page\n",
    "    # (this is useful for where to go next)\n",
    "    while numberVisited < maxPages and pagesToVisit != [] and not foundWord:\n",
    "        numberVisited = numberVisited +1\n",
    "        # Start from the beginning of our collection of pages to visit:\n",
    "        url = pagesToVisit[0]\n",
    "        pagesToVisit = pagesToVisit[1:]\n",
    "        try:\n",
    "            print(numberVisited, \"Visiting:\", url)\n",
    "            parser = LinkParser()\n",
    "            data, links = parser.getLinks(url)\n",
    "            if data.find(word)>-1:\n",
    "                foundWord = True\n",
    "                # Add the pages that we visited to the end of our collection\n",
    "                # of pages to visit:\n",
    "                pagesToVisit = pagesToVisit + links\n",
    "                print(\" **Success!**\")\n",
    "        except:\n",
    "            print(\" **Failed!**\")\n",
    "    if foundWord:\n",
    "        print(\"The word\", word, \"was found at\", url)\n",
    "    else:\n",
    "        print(\"Word never found\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Visiting: http://www.dreamhost.com\n",
      " **Success!**\n",
      "The word wordpress was found at http://www.dreamhost.com\n"
     ]
    }
   ],
   "source": [
    "spider(\"http://www.dreamhost.com\",\"wordpress\",200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Visiting: https://w3schools.com\n",
      " **Success!**\n",
      "The word css was found at https://w3schools.com\n"
     ]
    }
   ],
   "source": [
    "spider(\"https://w3schools.com\",\"css\",200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Robo. I will answer your queries about Chatbots. Greet me with a 'hi' to begin. If you want to exit, type 'bye'.You can then also access Management details.\n",
      "article 370 debate modi\n",
      "ROBO: article 370 debate modi This answer might be incorrect, please structure your query in a better way. If not, please contact management \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string \n",
    "f=open('newsdoc1.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()\n",
    "\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "word_tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    "\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize)\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you. Please contact the management\"\n",
    "        return robo_response\n",
    "    elif req_tfidf<0.5:\n",
    "        robo_response=robo_response+sent_tokens[idx+1]\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx+1]#remember senttoken[idx] is the token cosine similaritywise matched and retrieved\n",
    "        return robo_response\n",
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. Greet me with a 'hi' to begin. If you want to exit, type 'bye'.You can then also access Management details.\")\n",
    "while(flag==True):\n",
    "    user_response = input('')\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "words\t\t Doc1 Doc2\n",
      "\n",
      "ListExploreFor   : < newsdoc1.txt , 2 ,[ 0 28 ] >  0 \n",
      "\n",
      "EnterpriseJoin   : < newsdoc1.txt , 3 ,[ 1 29 34 ] >  0 \n",
      "\n",
      "for              : < newsdoc1.txt , 23 ,[ 2 26 30 35 42 103 144 185 264 293 300 307 315 349 405 446 493 572 601 608 615 623 657 ] >  < newsdoc2.txt , 25 ,[ 56 65 94 101 127 137 166 173 180 195 202 284 290 293 311 362 389 415 444 451 466 546 552 555 573 ] >  \n",
      "\n",
      "FreeLog          : < newsdoc1.txt , 3 ,[ 3 31 36 ] >  0 \n",
      "\n",
      "InLoupe          : < newsdoc1.txt , 1 ,[ 4 ] >  0 \n",
      "\n",
      "CopyExploreArts  : < newsdoc1.txt , 1 ,[ 5 ] >  0 \n",
      "\n",
      "and              : < newsdoc1.txt , 24 ,[ 6 11 15 50 61 67 108 119 125 192 324 354 358 374 383 410 421 427 500 632 662 666 682 691 ] >  < newsdoc2.txt , 14 ,[ 119 147 235 240 254 259 300 407 425 497 502 516 521 562 ] >  \n",
      "\n",
      "HumanitiesBusinessComputer  : < newsdoc1.txt , 1 ,[ 7 ] >  0 \n",
      "\n",
      "ScienceData      : < newsdoc1.txt , 1 ,[ 8 ] >  0 \n",
      "\n",
      "ScienceInformation  : < newsdoc1.txt , 1 ,[ 9 ] >  0 \n",
      "\n",
      "TechnologyHealthMath  : < newsdoc1.txt , 1 ,[ 10 ] >  0 \n",
      "\n",
      "LogicPersonal    : < newsdoc1.txt , 1 ,[ 12 ] >  0 \n",
      "\n",
      "DevelopmentPhysical  : < newsdoc1.txt , 1 ,[ 13 ] >  0 \n",
      "\n",
      "Science          : < newsdoc1.txt , 24 ,[ 14 54 56 66 112 114 124 242 267 270 340 366 371 373 414 416 426 550 575 578 648 674 679 681 ] >  0 \n",
      "\n",
      "EngineeringSocial  : < newsdoc1.txt , 1 ,[ 16 ] >  0 \n",
      "\n",
      "SciencesLanguage  : < newsdoc1.txt , 1 ,[ 17 ] >  0 \n",
      "\n",
      "LearningDegreesCertificatesExplore  : < newsdoc1.txt , 1 ,[ 18 ] >  0 \n",
      "\n",
      "all              : < newsdoc1.txt , 6 ,[ 19 76 96 98 134 436 ] >  0 \n",
      "\n",
      "of               : < newsdoc1.txt , 12 ,[ 20 77 135 243 258 319 328 437 551 566 627 636 ] >  < newsdoc2.txt , 16 ,[ 86 117 158 187 224 275 288 334 381 405 436 458 486 537 550 599 ] >  \n",
      "\n",
      "CourseraLoupe    : < newsdoc1.txt , 1 ,[ 21 ] >  0 \n",
      "\n",
      "CopyLoupe        : < newsdoc1.txt , 1 ,[ 22 ] >  0 \n",
      "\n",
      "CopyBrowseSearchFor  : < newsdoc1.txt , 1 ,[ 23 ] >  0 \n",
      "\n",
      "EnterpriseLog    : < newsdoc1.txt , 1 ,[ 24 ] >  0 \n",
      "\n",
      "InJoin           : < newsdoc1.txt , 1 ,[ 25 ] >  0 \n",
      "\n",
      "Free             : < newsdoc1.txt , 6 ,[ 27 43 104 145 406 447 ] >  0 \n",
      "\n",
      "In               : < newsdoc1.txt , 7 ,[ 32 37 45 106 142 408 444 ] >  0 \n",
      "\n",
      "ExploreFor       : < newsdoc1.txt , 1 ,[ 33 ] >  0 \n",
      "\n",
      "Explore          : < newsdoc1.txt , 7 ,[ 38 48 75 99 133 401 435 ] >  0 \n",
      "\n",
      "For              : < newsdoc1.txt , 9 ,[ 39 100 139 155 157 402 441 466 468 ] >  0 \n",
      "\n",
      "Enterprise       : < newsdoc1.txt , 9 ,[ 40 101 140 156 302 403 442 467 610 ] >  0 \n",
      "\n",
      "Join             : < newsdoc1.txt , 5 ,[ 41 102 143 404 445 ] >  0 \n",
      "\n",
      "Log              : < newsdoc1.txt , 5 ,[ 44 105 141 407 443 ] >  0 \n",
      "\n",
      "Loupe            : < newsdoc1.txt , 1 ,[ 46 ] >  0 \n",
      "\n",
      "Copy             : < newsdoc1.txt , 1 ,[ 47 ] >  0 \n",
      "\n",
      "Arts             : < newsdoc1.txt , 3 ,[ 49 107 409 ] >  0 \n",
      "\n",
      "Humanities       : < newsdoc1.txt , 3 ,[ 51 109 411 ] >  < newsdoc2.txt , 2 ,[ 118 406 ] >  \n",
      "\n",
      "Business         : < newsdoc1.txt , 11 ,[ 52 110 273 303 308 384 412 581 611 616 692 ] >  0 \n",
      "\n",
      "Computer         : < newsdoc1.txt , 7 ,[ 53 111 370 372 413 678 680 ] >  0 \n",
      "\n",
      "Data             : < newsdoc1.txt , 17 ,[ 55 113 221 266 269 280 339 352 365 415 529 574 577 588 647 660 673 ] >  0 \n",
      "\n",
      "Information      : < newsdoc1.txt , 5 ,[ 57 115 399 417 707 ] >  0 \n",
      "\n",
      "Technology       : < newsdoc1.txt , 5 ,[ 58 116 400 418 708 ] >  0 \n",
      "\n",
      "Health           : < newsdoc1.txt , 9 ,[ 59 117 256 317 395 419 564 625 703 ] >  0 \n",
      "\n",
      "Math             : < newsdoc1.txt , 3 ,[ 60 118 420 ] >  0 \n",
      "\n",
      "Logic            : < newsdoc1.txt , 3 ,[ 62 120 422 ] >  0 \n",
      "\n",
      "Personal         : < newsdoc1.txt , 3 ,[ 63 121 423 ] >  0 \n",
      "\n",
      "Development      : < newsdoc1.txt , 3 ,[ 64 122 424 ] >  0 \n",
      "\n",
      "Physical         : < newsdoc1.txt , 3 ,[ 65 123 425 ] >  0 \n",
      "\n",
      "Engineering      : < newsdoc1.txt , 13 ,[ 68 126 237 281 357 375 390 428 545 589 665 683 698 ] >  < newsdoc2.txt , 6 ,[ 87 159 264 382 437 526 ] >  \n",
      "\n",
      "Social           : < newsdoc1.txt , 3 ,[ 69 127 429 ] >  0 \n",
      "\n",
      "Sciences         : < newsdoc1.txt , 3 ,[ 70 128 430 ] >  < newsdoc2.txt , 2 ,[ 120 408 ] >  \n",
      "\n",
      "Language         : < newsdoc1.txt , 3 ,[ 71 129 431 ] >  0 \n",
      "\n",
      "Learning         : < newsdoc1.txt , 25 ,[ 72 93 130 194 204 206 210 246 262 291 295 348 381 432 453 502 512 514 518 554 570 599 603 656 689 ] >  < newsdoc2.txt , 3 ,[ 55 64 361 ] >  \n",
      "\n",
      "Degrees          : < newsdoc1.txt , 9 ,[ 73 131 154 376 385 433 465 684 693 ] >  < newsdoc2.txt , 4 ,[ 10 26 74 208 ] >  \n",
      "\n",
      "Certificates     : < newsdoc1.txt , 7 ,[ 74 132 151 153 434 462 464 ] >  < newsdoc2.txt , 4 ,[ 12 28 76 210 ] >  \n",
      "\n",
      "Coursera         : < newsdoc1.txt , 7 ,[ 78 83 86 136 146 438 457 ] >  0 \n",
      "\n",
      "See              : < newsdoc1.txt , 2 ,[ 79 448 ] >  0 \n",
      "\n",
      "All              : < newsdoc1.txt , 3 ,[ 80 88 449 ] >  < newsdoc2.txt , 2 ,[ 372 473 ] >  \n",
      "\n",
      "Learn            : < newsdoc1.txt , 4 ,[ 81 249 455 557 ] >  0 \n",
      "\n",
      "More             : < newsdoc1.txt , 3 ,[ 82 175 456 ] >  < newsdoc2.txt , 2 ,[ 71 368 ] >  \n",
      "\n",
      "©                : < newsdoc1.txt , 1 ,[ 84 ] >  < newsdoc2.txt , 1 ,[ 33 ] >  \n",
      "\n",
      "2019             : < newsdoc1.txt , 1 ,[ 85 ] >  0 \n",
      "\n",
      "Inc.             : < newsdoc1.txt , 1 ,[ 87 ] >  0 \n",
      "\n",
      "rights           : < newsdoc1.txt , 1 ,[ 89 ] >  0 \n",
      "\n",
      "reserved         : < newsdoc1.txt , 1 ,[ 90 ] >  0 \n",
      "\n",
      ".                : < newsdoc1.txt , 1 ,[ 91 ] >  < newsdoc2.txt , 11 ,[ 41 227 261 268 270 272 489 523 530 532 534 ] >  \n",
      "\n",
      "Online           : < newsdoc1.txt , 1 ,[ 92 ] >  < newsdoc2.txt , 20 ,[ 1 15 17 22 24 97 104 130 140 169 176 198 205 318 350 392 418 447 469 583 ] >  \n",
      "\n",
      "Programs         : < newsdoc1.txt , 1 ,[ 94 ] >  < newsdoc2.txt , 7 ,[ 14 30 46 78 212 352 474 ] >  \n",
      "\n",
      "Show             : < newsdoc1.txt , 2 ,[ 95 97 ] >  0 \n",
      "\n",
      "Browse           : < newsdoc1.txt , 2 ,[ 137 439 ] >  < newsdoc2.txt , 2 ,[ 371 472 ] >  \n",
      "\n",
      "Search           : < newsdoc1.txt , 2 ,[ 138 440 ] >  < newsdoc2.txt , 4 ,[ 73 329 370 594 ] >  \n",
      "\n",
      "About            : < newsdoc1.txt , 2 ,[ 147 458 ] >  < newsdoc2.txt , 2 ,[ 50 356 ] >  \n",
      "\n",
      "Leadership       : < newsdoc1.txt , 4 ,[ 148 260 459 568 ] >  0 \n",
      "\n",
      "Careers          : < newsdoc1.txt , 2 ,[ 149 460 ] >  0 \n",
      "\n",
      "Catalog          : < newsdoc1.txt , 2 ,[ 150 461 ] >  0 \n",
      "\n",
      "MasterTrack™     : < newsdoc1.txt , 2 ,[ 152 463 ] >  0 \n",
      "\n",
      "Government       : < newsdoc1.txt , 2 ,[ 158 469 ] >  0 \n",
      "\n",
      "Community        : < newsdoc1.txt , 1 ,[ 159 ] >  < newsdoc2.txt , 3 ,[ 54 63 360 ] >  \n",
      "\n",
      "Learners         : < newsdoc1.txt , 2 ,[ 160 470 ] >  0 \n",
      "\n",
      "Partners         : < newsdoc1.txt , 2 ,[ 161 471 ] >  < newsdoc2.txt , 2 ,[ 49 355 ] >  \n",
      "\n",
      "Developers       : < newsdoc1.txt , 2 ,[ 162 472 ] >  0 \n",
      "\n",
      "Beta             : < newsdoc1.txt , 2 ,[ 163 473 ] >  0 \n",
      "\n",
      "Testers          : < newsdoc1.txt , 2 ,[ 164 474 ] >  0 \n",
      "\n",
      "Translators      : < newsdoc1.txt , 2 ,[ 165 475 ] >  0 \n",
      "\n",
      "Connect          : < newsdoc1.txt , 1 ,[ 166 ] >  0 \n",
      "\n",
      "Blog             : < newsdoc1.txt , 4 ,[ 167 174 476 483 ] >  0 \n",
      "\n",
      "Facebook         : < newsdoc1.txt , 2 ,[ 168 477 ] >  < newsdoc2.txt , 2 ,[ 321 586 ] >  \n",
      "\n",
      "LinkedIn         : < newsdoc1.txt , 2 ,[ 169 478 ] >  0 \n",
      "\n",
      "Twitter          : < newsdoc1.txt , 2 ,[ 170 479 ] >  < newsdoc2.txt , 3 ,[ 31 322 587 ] >  \n",
      "\n",
      "Instagram        : < newsdoc1.txt , 2 ,[ 171 480 ] >  0 \n",
      "\n",
      "YouTube          : < newsdoc1.txt , 2 ,[ 172 481 ] >  < newsdoc2.txt , 3 ,[ 32 323 588 ] >  \n",
      "\n",
      "Tech             : < newsdoc1.txt , 2 ,[ 173 482 ] >  0 \n",
      "\n",
      "Terms            : < newsdoc1.txt , 2 ,[ 176 484 ] >  < newsdoc2.txt , 2 ,[ 333 598 ] >  \n",
      "\n",
      "Privacy          : < newsdoc1.txt , 2 ,[ 177 485 ] >  < newsdoc2.txt , 2 ,[ 336 601 ] >  \n",
      "\n",
      "Help             : < newsdoc1.txt , 2 ,[ 178 486 ] >  0 \n",
      "\n",
      "Accessibility    : < newsdoc1.txt , 2 ,[ 179 487 ] >  < newsdoc2.txt , 5 ,[ 53 62 340 359 605 ] >  \n",
      "\n",
      "Press            : < newsdoc1.txt , 2 ,[ 180 488 ] >  0 \n",
      "\n",
      "Contact          : < newsdoc1.txt , 2 ,[ 181 489 ] >  0 \n",
      "\n",
      "Directory        : < newsdoc1.txt , 2 ,[ 182 490 ] >  0 \n",
      "\n",
      "Affiliates       : < newsdoc1.txt , 2 ,[ 183 491 ] >  0 \n",
      "\n",
      "AI               : < newsdoc1.txt , 2 ,[ 184 492 ] >  0 \n",
      "\n",
      "Everyone         : < newsdoc1.txt , 2 ,[ 186 494 ] >  0 \n",
      "\n",
      "Introduction     : < newsdoc1.txt , 2 ,[ 187 495 ] >  0 \n",
      "\n",
      "to               : < newsdoc1.txt , 8 ,[ 188 217 248 287 496 525 556 595 ] >  < newsdoc2.txt , 4 ,[ 153 342 346 431 ] >  \n",
      "\n",
      "TensorFlow       : < newsdoc1.txt , 2 ,[ 189 497 ] >  0 \n",
      "\n",
      "Neural           : < newsdoc1.txt , 2 ,[ 190 498 ] >  0 \n",
      "\n",
      "Networks         : < newsdoc1.txt , 2 ,[ 191 499 ] >  0 \n",
      "\n",
      "Deep             : < newsdoc1.txt , 4 ,[ 193 261 501 569 ] >  0 \n",
      "\n",
      "Algorithms       : < newsdoc1.txt , 4 ,[ 195 199 503 507 ] >  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",                : < newsdoc1.txt , 4 ,[ 196 200 504 508 ] >  < newsdoc2.txt , 11 ,[ 18 38 131 141 248 298 305 419 510 560 567 ] >  \n",
      "\n",
      "Part             : < newsdoc1.txt , 4 ,[ 197 201 505 509 ] >  0 \n",
      "\n",
      "1                : < newsdoc1.txt , 2 ,[ 198 506 ] >  0 \n",
      "\n",
      "2                : < newsdoc1.txt , 2 ,[ 202 510 ] >  0 \n",
      "\n",
      "Machine          : < newsdoc1.txt , 14 ,[ 203 205 209 290 294 347 380 511 513 517 598 602 655 688 ] >  0 \n",
      "\n",
      "with             : < newsdoc1.txt , 12 ,[ 207 219 223 271 276 313 515 527 531 579 584 621 ] >  < newsdoc2.txt , 2 ,[ 81 376 ] >  \n",
      "\n",
      "Python           : < newsdoc1.txt , 8 ,[ 208 224 263 272 516 532 571 580 ] >  0 \n",
      "\n",
      "Using            : < newsdoc1.txt , 2 ,[ 211 519 ] >  0 \n",
      "\n",
      "Sas              : < newsdoc1.txt , 2 ,[ 212 520 ] >  0 \n",
      "\n",
      "Viya             : < newsdoc1.txt , 2 ,[ 213 521 ] >  0 \n",
      "\n",
      "R                : < newsdoc1.txt , 4 ,[ 214 314 522 622 ] >  0 \n",
      "\n",
      "Programming      : < newsdoc1.txt , 4 ,[ 215 218 523 526 ] >  0 \n",
      "\n",
      "Intro            : < newsdoc1.txt , 2 ,[ 216 524 ] >  0 \n",
      "\n",
      "Matlab           : < newsdoc1.txt , 2 ,[ 220 528 ] >  0 \n",
      "\n",
      "Analysis         : < newsdoc1.txt , 6 ,[ 222 312 353 530 620 661 ] >  0 \n",
      "\n",
      "AWS              : < newsdoc1.txt , 2 ,[ 225 533 ] >  0 \n",
      "\n",
      "Fundamentals     : < newsdoc1.txt , 6 ,[ 226 234 318 534 542 626 ] >  0 \n",
      "\n",
      ":                : < newsdoc1.txt , 2 ,[ 227 535 ] >  < newsdoc2.txt , 17 ,[ 9 96 103 112 129 139 149 168 175 197 204 391 400 417 427 446 468 ] >  \n",
      "\n",
      "Going            : < newsdoc1.txt , 2 ,[ 228 536 ] >  0 \n",
      "\n",
      "Cloud            : < newsdoc1.txt , 8 ,[ 229 232 278 284 537 540 586 592 ] >  0 \n",
      "\n",
      "Native           : < newsdoc1.txt , 2 ,[ 230 538 ] >  0 \n",
      "\n",
      "Google           : < newsdoc1.txt , 8 ,[ 231 277 283 331 539 585 591 639 ] >  0 \n",
      "\n",
      "Platform         : < newsdoc1.txt , 6 ,[ 233 279 285 541 587 593 ] >  0 \n",
      "\n",
      "Site             : < newsdoc1.txt , 2 ,[ 235 543 ] >  0 \n",
      "\n",
      "Reliability      : < newsdoc1.txt , 2 ,[ 236 544 ] >  0 \n",
      "\n",
      "Speak            : < newsdoc1.txt , 2 ,[ 238 546 ] >  0 \n",
      "\n",
      "English          : < newsdoc1.txt , 2 ,[ 239 547 ] >  0 \n",
      "\n",
      "Professionally   : < newsdoc1.txt , 2 ,[ 240 548 ] >  0 \n",
      "\n",
      "The              : < newsdoc1.txt , 2 ,[ 241 549 ] >  0 \n",
      "\n",
      "Well             : < newsdoc1.txt , 2 ,[ 244 552 ] >  0 \n",
      "\n",
      "Being            : < newsdoc1.txt , 2 ,[ 245 553 ] >  0 \n",
      "\n",
      "How              : < newsdoc1.txt , 2 ,[ 247 555 ] >  0 \n",
      "\n",
      "Financial        : < newsdoc1.txt , 2 ,[ 250 558 ] >  0 \n",
      "\n",
      "Markets          : < newsdoc1.txt , 2 ,[ 251 559 ] >  0 \n",
      "\n",
      "Hypothesis       : < newsdoc1.txt , 2 ,[ 252 560 ] >  0 \n",
      "\n",
      "Testing          : < newsdoc1.txt , 2 ,[ 253 561 ] >  0 \n",
      "\n",
      "in               : < newsdoc1.txt , 14 ,[ 254 364 369 379 388 393 398 562 672 677 687 696 701 706 ] >  < newsdoc2.txt , 6 ,[ 221 252 281 483 514 543 ] >  \n",
      "\n",
      "Public           : < newsdoc1.txt , 6 ,[ 255 316 394 563 624 702 ] >  0 \n",
      "\n",
      "Foundations      : < newsdoc1.txt , 6 ,[ 257 274 327 565 582 635 ] >  0 \n",
      "\n",
      "Everyday         : < newsdoc1.txt , 2 ,[ 259 567 ] >  0 \n",
      "\n",
      "Everybody        : < newsdoc1.txt , 2 ,[ 265 573 ] >  0 \n",
      "\n",
      "Applied          : < newsdoc1.txt , 4 ,[ 268 341 576 649 ] >  0 \n",
      "\n",
      "Architecting     : < newsdoc1.txt , 2 ,[ 275 583 ] >  0 \n",
      "\n",
      "on               : < newsdoc1.txt , 2 ,[ 282 590 ] >  0 \n",
      "\n",
      "Excel            : < newsdoc1.txt , 4 ,[ 286 305 594 613 ] >  0 \n",
      "\n",
      "MySQL            : < newsdoc1.txt , 2 ,[ 288 596 ] >  0 \n",
      "\n",
      "Advanced         : < newsdoc1.txt , 2 ,[ 289 597 ] >  0 \n",
      "\n",
      "Mathematics      : < newsdoc1.txt , 2 ,[ 292 600 ] >  0 \n",
      "\n",
      "Self-Driving     : < newsdoc1.txt , 2 ,[ 296 604 ] >  0 \n",
      "\n",
      "Cars             : < newsdoc1.txt , 2 ,[ 297 605 ] >  0 \n",
      "\n",
      "Blockchain       : < newsdoc1.txt , 2 ,[ 298 606 ] >  < newsdoc2.txt , 2 ,[ 146 424 ] >  \n",
      "\n",
      "Revolution       : < newsdoc1.txt , 2 ,[ 299 607 ] >  0 \n",
      "\n",
      "the              : < newsdoc1.txt , 2 ,[ 301 609 ] >  < newsdoc2.txt , 8 ,[ 108 233 286 312 396 495 548 574 ] >  \n",
      "\n",
      "Analytics        : < newsdoc1.txt , 4 ,[ 304 350 612 658 ] >  0 \n",
      "\n",
      "Skills           : < newsdoc1.txt , 2 ,[ 306 614 ] >  0 \n",
      "\n",
      "Digital          : < newsdoc1.txt , 2 ,[ 309 617 ] >  < newsdoc2.txt , 4 ,[ 214 228 476 490 ] >  \n",
      "\n",
      "Marketing        : < newsdoc1.txt , 2 ,[ 310 618 ] >  0 \n",
      "\n",
      "Statistical      : < newsdoc1.txt , 2 ,[ 311 619 ] >  0 \n",
      "\n",
      "Immunology       : < newsdoc1.txt , 2 ,[ 320 628 ] >  0 \n",
      "\n",
      "Anatomy          : < newsdoc1.txt , 2 ,[ 321 629 ] >  0 \n",
      "\n",
      "Managing         : < newsdoc1.txt , 2 ,[ 322 630 ] >  0 \n",
      "\n",
      "Innovation       : < newsdoc1.txt , 2 ,[ 323 631 ] >  < newsdoc2.txt , 2 ,[ 239 501 ] >  \n",
      "\n",
      "Design           : < newsdoc1.txt , 4 ,[ 325 361 633 669 ] >  0 \n",
      "\n",
      "Thinking         : < newsdoc1.txt , 2 ,[ 326 634 ] >  0 \n",
      "\n",
      "Positive         : < newsdoc1.txt , 2 ,[ 329 637 ] >  0 \n",
      "\n",
      "Psychology       : < newsdoc1.txt , 2 ,[ 330 638 ] >  0 \n",
      "\n",
      "IT               : < newsdoc1.txt , 2 ,[ 332 640 ] >  0 \n",
      "\n",
      "Support          : < newsdoc1.txt , 2 ,[ 333 641 ] >  0 \n",
      "\n",
      "IBM              : < newsdoc1.txt , 6 ,[ 334 338 344 642 646 652 ] >  0 \n",
      "\n",
      "Customer         : < newsdoc1.txt , 2 ,[ 335 643 ] >  0 \n",
      "\n",
      "Engagement       : < newsdoc1.txt , 2 ,[ 336 644 ] >  0 \n",
      "\n",
      "Specialist       : < newsdoc1.txt , 2 ,[ 337 645 ] >  0 \n",
      "\n",
      "Project          : < newsdoc1.txt , 2 ,[ 342 650 ] >  0 \n",
      "\n",
      "Management       : < newsdoc1.txt , 4 ,[ 343 359 651 667 ] >  0 \n",
      "\n",
      "Artificial       : < newsdoc1.txt , 2 ,[ 345 653 ] >  0 \n",
      "\n",
      "Intelligence     : < newsdoc1.txt , 2 ,[ 346 654 ] >  0 \n",
      "\n",
      "Spatial          : < newsdoc1.txt , 2 ,[ 351 659 ] >  0 \n",
      "\n",
      "Visualization    : < newsdoc1.txt , 2 ,[ 355 663 ] >  0 \n",
      "\n",
      "Construction     : < newsdoc1.txt , 2 ,[ 356 664 ] >  0 \n",
      "\n",
      "Instructional    : < newsdoc1.txt , 2 ,[ 360 668 ] >  0 \n",
      "\n",
      "Master           : < newsdoc1.txt , 10 ,[ 362 377 386 391 396 670 685 694 699 704 ] >  0 \n",
      "\n",
      "'s               : < newsdoc1.txt , 10 ,[ 363 378 387 392 397 671 686 695 700 705 ] >  0 \n",
      "\n",
      "Bachelors        : < newsdoc1.txt , 2 ,[ 367 675 ] >  0 \n",
      "\n",
      "Degree           : < newsdoc1.txt , 2 ,[ 368 676 ] >  < newsdoc2.txt , 2 ,[ 266 528 ] >  \n",
      "\n",
      "MBA              : < newsdoc1.txt , 2 ,[ 382 690 ] >  0 \n",
      "\n",
      "Electrical       : < newsdoc1.txt , 2 ,[ 389 697 ] >  0 \n",
      "\n",
      "New              : < newsdoc1.txt , 1 ,[ 450 ] >  0 \n",
      "\n",
      "!                : < newsdoc1.txt , 1 ,[ 451 ] >  0 \n",
      "\n",
      "Reinforcement    : < newsdoc1.txt , 1 ,[ 452 ] >  0 \n",
      "\n",
      "Specialization   : < newsdoc1.txt , 1 ,[ 454 ] >  0 \n",
      "\n",
      "number of words in this site is:198\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "words\t\t Doc1 Doc2\n",
      "\n",
      "ListExploreFor   : < newsdoc1.txt , 2 ,[ 0 28 ] >  0 \n",
      "\n",
      "EnterpriseJoin   : < newsdoc1.txt , 3 ,[ 1 29 34 ] >  0 \n",
      "\n",
      "for              : < newsdoc1.txt , 23 ,[ 2 26 30 35 42 103 144 185 264 293 300 307 315 349 405 446 493 572 601 608 615 623 657 ] >  < newsdoc2.txt , 25 ,[ 56 65 94 101 127 137 166 173 180 195 202 284 290 293 311 362 389 415 444 451 466 546 552 555 573 ] >  \n",
      "\n",
      "FreeLog          : < newsdoc1.txt , 3 ,[ 3 31 36 ] >  0 \n",
      "\n",
      "InLoupe          : < newsdoc1.txt , 1 ,[ 4 ] >  0 \n",
      "\n",
      "CopyExploreArts  : < newsdoc1.txt , 1 ,[ 5 ] >  0 \n",
      "\n",
      "and              : < newsdoc1.txt , 24 ,[ 6 11 15 50 61 67 108 119 125 192 324 354 358 374 383 410 421 427 500 632 662 666 682 691 ] >  < newsdoc2.txt , 14 ,[ 119 147 235 240 254 259 300 407 425 497 502 516 521 562 ] >  \n",
      "\n",
      "HumanitiesBusinessComputer  : < newsdoc1.txt , 1 ,[ 7 ] >  0 \n",
      "\n",
      "ScienceData      : < newsdoc1.txt , 1 ,[ 8 ] >  0 \n",
      "\n",
      "ScienceInformation  : < newsdoc1.txt , 1 ,[ 9 ] >  0 \n",
      "\n",
      "TechnologyHealthMath  : < newsdoc1.txt , 1 ,[ 10 ] >  0 \n",
      "\n",
      "LogicPersonal    : < newsdoc1.txt , 1 ,[ 12 ] >  0 \n",
      "\n",
      "DevelopmentPhysical  : < newsdoc1.txt , 1 ,[ 13 ] >  0 \n",
      "\n",
      "Science          : < newsdoc1.txt , 24 ,[ 14 54 56 66 112 114 124 242 267 270 340 366 371 373 414 416 426 550 575 578 648 674 679 681 ] >  0 \n",
      "\n",
      "EngineeringSocial  : < newsdoc1.txt , 1 ,[ 16 ] >  0 \n",
      "\n",
      "SciencesLanguage  : < newsdoc1.txt , 1 ,[ 17 ] >  0 \n",
      "\n",
      "LearningDegreesCertificatesExplore  : < newsdoc1.txt , 1 ,[ 18 ] >  0 \n",
      "\n",
      "all              : < newsdoc1.txt , 6 ,[ 19 76 96 98 134 436 ] >  0 \n",
      "\n",
      "of               : < newsdoc1.txt , 12 ,[ 20 77 135 243 258 319 328 437 551 566 627 636 ] >  < newsdoc2.txt , 16 ,[ 86 117 158 187 224 275 288 334 381 405 436 458 486 537 550 599 ] >  \n",
      "\n",
      "CourseraLoupe    : < newsdoc1.txt , 1 ,[ 21 ] >  0 \n",
      "\n",
      "CopyLoupe        : < newsdoc1.txt , 1 ,[ 22 ] >  0 \n",
      "\n",
      "CopyBrowseSearchFor  : < newsdoc1.txt , 1 ,[ 23 ] >  0 \n",
      "\n",
      "EnterpriseLog    : < newsdoc1.txt , 1 ,[ 24 ] >  0 \n",
      "\n",
      "InJoin           : < newsdoc1.txt , 1 ,[ 25 ] >  0 \n",
      "\n",
      "Free             : < newsdoc1.txt , 6 ,[ 27 43 104 145 406 447 ] >  0 \n",
      "\n",
      "In               : < newsdoc1.txt , 7 ,[ 32 37 45 106 142 408 444 ] >  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExploreFor       : < newsdoc1.txt , 1 ,[ 33 ] >  0 \n",
      "\n",
      "Explore          : < newsdoc1.txt , 7 ,[ 38 48 75 99 133 401 435 ] >  0 \n",
      "\n",
      "For              : < newsdoc1.txt , 9 ,[ 39 100 139 155 157 402 441 466 468 ] >  0 \n",
      "\n",
      "Enterprise       : < newsdoc1.txt , 9 ,[ 40 101 140 156 302 403 442 467 610 ] >  0 \n",
      "\n",
      "Join             : < newsdoc1.txt , 5 ,[ 41 102 143 404 445 ] >  0 \n",
      "\n",
      "Log              : < newsdoc1.txt , 5 ,[ 44 105 141 407 443 ] >  0 \n",
      "\n",
      "Loupe            : < newsdoc1.txt , 1 ,[ 46 ] >  0 \n",
      "\n",
      "Copy             : < newsdoc1.txt , 1 ,[ 47 ] >  0 \n",
      "\n",
      "Arts             : < newsdoc1.txt , 3 ,[ 49 107 409 ] >  0 \n",
      "\n",
      "Humanities       : < newsdoc1.txt , 3 ,[ 51 109 411 ] >  < newsdoc2.txt , 2 ,[ 118 406 ] >  \n",
      "\n",
      "Business         : < newsdoc1.txt , 11 ,[ 52 110 273 303 308 384 412 581 611 616 692 ] >  0 \n",
      "\n",
      "Computer         : < newsdoc1.txt , 7 ,[ 53 111 370 372 413 678 680 ] >  0 \n",
      "\n",
      "Data             : < newsdoc1.txt , 17 ,[ 55 113 221 266 269 280 339 352 365 415 529 574 577 588 647 660 673 ] >  0 \n",
      "\n",
      "Information      : < newsdoc1.txt , 5 ,[ 57 115 399 417 707 ] >  0 \n",
      "\n",
      "Technology       : < newsdoc1.txt , 5 ,[ 58 116 400 418 708 ] >  0 \n",
      "\n",
      "Health           : < newsdoc1.txt , 9 ,[ 59 117 256 317 395 419 564 625 703 ] >  0 \n",
      "\n",
      "Math             : < newsdoc1.txt , 3 ,[ 60 118 420 ] >  0 \n",
      "\n",
      "Logic            : < newsdoc1.txt , 3 ,[ 62 120 422 ] >  0 \n",
      "\n",
      "Personal         : < newsdoc1.txt , 3 ,[ 63 121 423 ] >  0 \n",
      "\n",
      "Development      : < newsdoc1.txt , 3 ,[ 64 122 424 ] >  0 \n",
      "\n",
      "Physical         : < newsdoc1.txt , 3 ,[ 65 123 425 ] >  0 \n",
      "\n",
      "Engineering      : < newsdoc1.txt , 13 ,[ 68 126 237 281 357 375 390 428 545 589 665 683 698 ] >  < newsdoc2.txt , 6 ,[ 87 159 264 382 437 526 ] >  \n",
      "\n",
      "Social           : < newsdoc1.txt , 3 ,[ 69 127 429 ] >  0 \n",
      "\n",
      "Sciences         : < newsdoc1.txt , 3 ,[ 70 128 430 ] >  < newsdoc2.txt , 2 ,[ 120 408 ] >  \n",
      "\n",
      "Language         : < newsdoc1.txt , 3 ,[ 71 129 431 ] >  0 \n",
      "\n",
      "Learning         : < newsdoc1.txt , 25 ,[ 72 93 130 194 204 206 210 246 262 291 295 348 381 432 453 502 512 514 518 554 570 599 603 656 689 ] >  < newsdoc2.txt , 3 ,[ 55 64 361 ] >  \n",
      "\n",
      "Degrees          : < newsdoc1.txt , 9 ,[ 73 131 154 376 385 433 465 684 693 ] >  < newsdoc2.txt , 4 ,[ 10 26 74 208 ] >  \n",
      "\n",
      "Certificates     : < newsdoc1.txt , 7 ,[ 74 132 151 153 434 462 464 ] >  < newsdoc2.txt , 4 ,[ 12 28 76 210 ] >  \n",
      "\n",
      "Coursera         : < newsdoc1.txt , 7 ,[ 78 83 86 136 146 438 457 ] >  0 \n",
      "\n",
      "See              : < newsdoc1.txt , 2 ,[ 79 448 ] >  0 \n",
      "\n",
      "All              : < newsdoc1.txt , 3 ,[ 80 88 449 ] >  < newsdoc2.txt , 2 ,[ 372 473 ] >  \n",
      "\n",
      "Learn            : < newsdoc1.txt , 4 ,[ 81 249 455 557 ] >  0 \n",
      "\n",
      "More             : < newsdoc1.txt , 3 ,[ 82 175 456 ] >  < newsdoc2.txt , 2 ,[ 71 368 ] >  \n",
      "\n",
      "©                : < newsdoc1.txt , 1 ,[ 84 ] >  < newsdoc2.txt , 1 ,[ 33 ] >  \n",
      "\n",
      "2019             : < newsdoc1.txt , 1 ,[ 85 ] >  0 \n",
      "\n",
      "Inc.             : < newsdoc1.txt , 1 ,[ 87 ] >  0 \n",
      "\n",
      "rights           : < newsdoc1.txt , 1 ,[ 89 ] >  0 \n",
      "\n",
      "reserved         : < newsdoc1.txt , 1 ,[ 90 ] >  0 \n",
      "\n",
      ".                : < newsdoc1.txt , 1 ,[ 91 ] >  < newsdoc2.txt , 11 ,[ 41 227 261 268 270 272 489 523 530 532 534 ] >  \n",
      "\n",
      "Online           : < newsdoc1.txt , 1 ,[ 92 ] >  < newsdoc2.txt , 20 ,[ 1 15 17 22 24 97 104 130 140 169 176 198 205 318 350 392 418 447 469 583 ] >  \n",
      "\n",
      "Programs         : < newsdoc1.txt , 1 ,[ 94 ] >  < newsdoc2.txt , 7 ,[ 14 30 46 78 212 352 474 ] >  \n",
      "\n",
      "Show             : < newsdoc1.txt , 2 ,[ 95 97 ] >  0 \n",
      "\n",
      "Browse           : < newsdoc1.txt , 2 ,[ 137 439 ] >  < newsdoc2.txt , 2 ,[ 371 472 ] >  \n",
      "\n",
      "Search           : < newsdoc1.txt , 2 ,[ 138 440 ] >  < newsdoc2.txt , 4 ,[ 73 329 370 594 ] >  \n",
      "\n",
      "About            : < newsdoc1.txt , 2 ,[ 147 458 ] >  < newsdoc2.txt , 2 ,[ 50 356 ] >  \n",
      "\n",
      "Leadership       : < newsdoc1.txt , 4 ,[ 148 260 459 568 ] >  0 \n",
      "\n",
      "Careers          : < newsdoc1.txt , 2 ,[ 149 460 ] >  0 \n",
      "\n",
      "Catalog          : < newsdoc1.txt , 2 ,[ 150 461 ] >  0 \n",
      "\n",
      "MasterTrack™     : < newsdoc1.txt , 2 ,[ 152 463 ] >  0 \n",
      "\n",
      "Government       : < newsdoc1.txt , 2 ,[ 158 469 ] >  0 \n",
      "\n",
      "Community        : < newsdoc1.txt , 1 ,[ 159 ] >  < newsdoc2.txt , 3 ,[ 54 63 360 ] >  \n",
      "\n",
      "Learners         : < newsdoc1.txt , 2 ,[ 160 470 ] >  0 \n",
      "\n",
      "Partners         : < newsdoc1.txt , 2 ,[ 161 471 ] >  < newsdoc2.txt , 2 ,[ 49 355 ] >  \n",
      "\n",
      "Developers       : < newsdoc1.txt , 2 ,[ 162 472 ] >  0 \n",
      "\n",
      "Beta             : < newsdoc1.txt , 2 ,[ 163 473 ] >  0 \n",
      "\n",
      "Testers          : < newsdoc1.txt , 2 ,[ 164 474 ] >  0 \n",
      "\n",
      "Translators      : < newsdoc1.txt , 2 ,[ 165 475 ] >  0 \n",
      "\n",
      "Connect          : < newsdoc1.txt , 1 ,[ 166 ] >  0 \n",
      "\n",
      "Blog             : < newsdoc1.txt , 4 ,[ 167 174 476 483 ] >  0 \n",
      "\n",
      "Facebook         : < newsdoc1.txt , 2 ,[ 168 477 ] >  < newsdoc2.txt , 2 ,[ 321 586 ] >  \n",
      "\n",
      "LinkedIn         : < newsdoc1.txt , 2 ,[ 169 478 ] >  0 \n",
      "\n",
      "Twitter          : < newsdoc1.txt , 2 ,[ 170 479 ] >  < newsdoc2.txt , 3 ,[ 31 322 587 ] >  \n",
      "\n",
      "Instagram        : < newsdoc1.txt , 2 ,[ 171 480 ] >  0 \n",
      "\n",
      "YouTube          : < newsdoc1.txt , 2 ,[ 172 481 ] >  < newsdoc2.txt , 3 ,[ 32 323 588 ] >  \n",
      "\n",
      "Tech             : < newsdoc1.txt , 2 ,[ 173 482 ] >  0 \n",
      "\n",
      "Terms            : < newsdoc1.txt , 2 ,[ 176 484 ] >  < newsdoc2.txt , 2 ,[ 333 598 ] >  \n",
      "\n",
      "Privacy          : < newsdoc1.txt , 2 ,[ 177 485 ] >  < newsdoc2.txt , 2 ,[ 336 601 ] >  \n",
      "\n",
      "Help             : < newsdoc1.txt , 2 ,[ 178 486 ] >  0 \n",
      "\n",
      "Accessibility    : < newsdoc1.txt , 2 ,[ 179 487 ] >  < newsdoc2.txt , 5 ,[ 53 62 340 359 605 ] >  \n",
      "\n",
      "Press            : < newsdoc1.txt , 2 ,[ 180 488 ] >  0 \n",
      "\n",
      "Contact          : < newsdoc1.txt , 2 ,[ 181 489 ] >  0 \n",
      "\n",
      "Directory        : < newsdoc1.txt , 2 ,[ 182 490 ] >  0 \n",
      "\n",
      "Affiliates       : < newsdoc1.txt , 2 ,[ 183 491 ] >  0 \n",
      "\n",
      "AI               : < newsdoc1.txt , 2 ,[ 184 492 ] >  0 \n",
      "\n",
      "Everyone         : < newsdoc1.txt , 2 ,[ 186 494 ] >  0 \n",
      "\n",
      "Introduction     : < newsdoc1.txt , 2 ,[ 187 495 ] >  0 \n",
      "\n",
      "to               : < newsdoc1.txt , 8 ,[ 188 217 248 287 496 525 556 595 ] >  < newsdoc2.txt , 4 ,[ 153 342 346 431 ] >  \n",
      "\n",
      "TensorFlow       : < newsdoc1.txt , 2 ,[ 189 497 ] >  0 \n",
      "\n",
      "Neural           : < newsdoc1.txt , 2 ,[ 190 498 ] >  0 \n",
      "\n",
      "Networks         : < newsdoc1.txt , 2 ,[ 191 499 ] >  0 \n",
      "\n",
      "Deep             : < newsdoc1.txt , 4 ,[ 193 261 501 569 ] >  0 \n",
      "\n",
      "Algorithms       : < newsdoc1.txt , 4 ,[ 195 199 503 507 ] >  0 \n",
      "\n",
      ",                : < newsdoc1.txt , 4 ,[ 196 200 504 508 ] >  < newsdoc2.txt , 11 ,[ 18 38 131 141 248 298 305 419 510 560 567 ] >  \n",
      "\n",
      "Part             : < newsdoc1.txt , 4 ,[ 197 201 505 509 ] >  0 \n",
      "\n",
      "1                : < newsdoc1.txt , 2 ,[ 198 506 ] >  0 \n",
      "\n",
      "2                : < newsdoc1.txt , 2 ,[ 202 510 ] >  0 \n",
      "\n",
      "Machine          : < newsdoc1.txt , 14 ,[ 203 205 209 290 294 347 380 511 513 517 598 602 655 688 ] >  0 \n",
      "\n",
      "with             : < newsdoc1.txt , 12 ,[ 207 219 223 271 276 313 515 527 531 579 584 621 ] >  < newsdoc2.txt , 2 ,[ 81 376 ] >  \n",
      "\n",
      "Python           : < newsdoc1.txt , 8 ,[ 208 224 263 272 516 532 571 580 ] >  0 \n",
      "\n",
      "Using            : < newsdoc1.txt , 2 ,[ 211 519 ] >  0 \n",
      "\n",
      "Sas              : < newsdoc1.txt , 2 ,[ 212 520 ] >  0 \n",
      "\n",
      "Viya             : < newsdoc1.txt , 2 ,[ 213 521 ] >  0 \n",
      "\n",
      "R                : < newsdoc1.txt , 4 ,[ 214 314 522 622 ] >  0 \n",
      "\n",
      "Programming      : < newsdoc1.txt , 4 ,[ 215 218 523 526 ] >  0 \n",
      "\n",
      "Intro            : < newsdoc1.txt , 2 ,[ 216 524 ] >  0 \n",
      "\n",
      "Matlab           : < newsdoc1.txt , 2 ,[ 220 528 ] >  0 \n",
      "\n",
      "Analysis         : < newsdoc1.txt , 6 ,[ 222 312 353 530 620 661 ] >  0 \n",
      "\n",
      "AWS              : < newsdoc1.txt , 2 ,[ 225 533 ] >  0 \n",
      "\n",
      "Fundamentals     : < newsdoc1.txt , 6 ,[ 226 234 318 534 542 626 ] >  0 \n",
      "\n",
      ":                : < newsdoc1.txt , 2 ,[ 227 535 ] >  < newsdoc2.txt , 17 ,[ 9 96 103 112 129 139 149 168 175 197 204 391 400 417 427 446 468 ] >  \n",
      "\n",
      "Going            : < newsdoc1.txt , 2 ,[ 228 536 ] >  0 \n",
      "\n",
      "Cloud            : < newsdoc1.txt , 8 ,[ 229 232 278 284 537 540 586 592 ] >  0 \n",
      "\n",
      "Native           : < newsdoc1.txt , 2 ,[ 230 538 ] >  0 \n",
      "\n",
      "Google           : < newsdoc1.txt , 8 ,[ 231 277 283 331 539 585 591 639 ] >  0 \n",
      "\n",
      "Platform         : < newsdoc1.txt , 6 ,[ 233 279 285 541 587 593 ] >  0 \n",
      "\n",
      "Site             : < newsdoc1.txt , 2 ,[ 235 543 ] >  0 \n",
      "\n",
      "Reliability      : < newsdoc1.txt , 2 ,[ 236 544 ] >  0 \n",
      "\n",
      "Speak            : < newsdoc1.txt , 2 ,[ 238 546 ] >  0 \n",
      "\n",
      "English          : < newsdoc1.txt , 2 ,[ 239 547 ] >  0 \n",
      "\n",
      "Professionally   : < newsdoc1.txt , 2 ,[ 240 548 ] >  0 \n",
      "\n",
      "The              : < newsdoc1.txt , 2 ,[ 241 549 ] >  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well             : < newsdoc1.txt , 2 ,[ 244 552 ] >  0 \n",
      "\n",
      "Being            : < newsdoc1.txt , 2 ,[ 245 553 ] >  0 \n",
      "\n",
      "How              : < newsdoc1.txt , 2 ,[ 247 555 ] >  0 \n",
      "\n",
      "Financial        : < newsdoc1.txt , 2 ,[ 250 558 ] >  0 \n",
      "\n",
      "Markets          : < newsdoc1.txt , 2 ,[ 251 559 ] >  0 \n",
      "\n",
      "Hypothesis       : < newsdoc1.txt , 2 ,[ 252 560 ] >  0 \n",
      "\n",
      "Testing          : < newsdoc1.txt , 2 ,[ 253 561 ] >  0 \n",
      "\n",
      "in               : < newsdoc1.txt , 14 ,[ 254 364 369 379 388 393 398 562 672 677 687 696 701 706 ] >  < newsdoc2.txt , 6 ,[ 221 252 281 483 514 543 ] >  \n",
      "\n",
      "Public           : < newsdoc1.txt , 6 ,[ 255 316 394 563 624 702 ] >  0 \n",
      "\n",
      "Foundations      : < newsdoc1.txt , 6 ,[ 257 274 327 565 582 635 ] >  0 \n",
      "\n",
      "Everyday         : < newsdoc1.txt , 2 ,[ 259 567 ] >  0 \n",
      "\n",
      "Everybody        : < newsdoc1.txt , 2 ,[ 265 573 ] >  0 \n",
      "\n",
      "Applied          : < newsdoc1.txt , 4 ,[ 268 341 576 649 ] >  0 \n",
      "\n",
      "Architecting     : < newsdoc1.txt , 2 ,[ 275 583 ] >  0 \n",
      "\n",
      "on               : < newsdoc1.txt , 2 ,[ 282 590 ] >  0 \n",
      "\n",
      "Excel            : < newsdoc1.txt , 4 ,[ 286 305 594 613 ] >  0 \n",
      "\n",
      "MySQL            : < newsdoc1.txt , 2 ,[ 288 596 ] >  0 \n",
      "\n",
      "Advanced         : < newsdoc1.txt , 2 ,[ 289 597 ] >  0 \n",
      "\n",
      "Mathematics      : < newsdoc1.txt , 2 ,[ 292 600 ] >  0 \n",
      "\n",
      "Self-Driving     : < newsdoc1.txt , 2 ,[ 296 604 ] >  0 \n",
      "\n",
      "Cars             : < newsdoc1.txt , 2 ,[ 297 605 ] >  0 \n",
      "\n",
      "Blockchain       : < newsdoc1.txt , 2 ,[ 298 606 ] >  < newsdoc2.txt , 2 ,[ 146 424 ] >  \n",
      "\n",
      "Revolution       : < newsdoc1.txt , 2 ,[ 299 607 ] >  0 \n",
      "\n",
      "the              : < newsdoc1.txt , 2 ,[ 301 609 ] >  < newsdoc2.txt , 8 ,[ 108 233 286 312 396 495 548 574 ] >  \n",
      "\n",
      "Analytics        : < newsdoc1.txt , 4 ,[ 304 350 612 658 ] >  0 \n",
      "\n",
      "Skills           : < newsdoc1.txt , 2 ,[ 306 614 ] >  0 \n",
      "\n",
      "Digital          : < newsdoc1.txt , 2 ,[ 309 617 ] >  < newsdoc2.txt , 4 ,[ 214 228 476 490 ] >  \n",
      "\n",
      "Marketing        : < newsdoc1.txt , 2 ,[ 310 618 ] >  0 \n",
      "\n",
      "Statistical      : < newsdoc1.txt , 2 ,[ 311 619 ] >  0 \n",
      "\n",
      "Immunology       : < newsdoc1.txt , 2 ,[ 320 628 ] >  0 \n",
      "\n",
      "Anatomy          : < newsdoc1.txt , 2 ,[ 321 629 ] >  0 \n",
      "\n",
      "Managing         : < newsdoc1.txt , 2 ,[ 322 630 ] >  0 \n",
      "\n",
      "Innovation       : < newsdoc1.txt , 2 ,[ 323 631 ] >  < newsdoc2.txt , 2 ,[ 239 501 ] >  \n",
      "\n",
      "Design           : < newsdoc1.txt , 4 ,[ 325 361 633 669 ] >  0 \n",
      "\n",
      "Thinking         : < newsdoc1.txt , 2 ,[ 326 634 ] >  0 \n",
      "\n",
      "Positive         : < newsdoc1.txt , 2 ,[ 329 637 ] >  0 \n",
      "\n",
      "Psychology       : < newsdoc1.txt , 2 ,[ 330 638 ] >  0 \n",
      "\n",
      "IT               : < newsdoc1.txt , 2 ,[ 332 640 ] >  0 \n",
      "\n",
      "Support          : < newsdoc1.txt , 2 ,[ 333 641 ] >  0 \n",
      "\n",
      "IBM              : < newsdoc1.txt , 6 ,[ 334 338 344 642 646 652 ] >  0 \n",
      "\n",
      "Customer         : < newsdoc1.txt , 2 ,[ 335 643 ] >  0 \n",
      "\n",
      "Engagement       : < newsdoc1.txt , 2 ,[ 336 644 ] >  0 \n",
      "\n",
      "Specialist       : < newsdoc1.txt , 2 ,[ 337 645 ] >  0 \n",
      "\n",
      "Project          : < newsdoc1.txt , 2 ,[ 342 650 ] >  0 \n",
      "\n",
      "Management       : < newsdoc1.txt , 4 ,[ 343 359 651 667 ] >  0 \n",
      "\n",
      "Artificial       : < newsdoc1.txt , 2 ,[ 345 653 ] >  0 \n",
      "\n",
      "Intelligence     : < newsdoc1.txt , 2 ,[ 346 654 ] >  0 \n",
      "\n",
      "Spatial          : < newsdoc1.txt , 2 ,[ 351 659 ] >  0 \n",
      "\n",
      "Visualization    : < newsdoc1.txt , 2 ,[ 355 663 ] >  0 \n",
      "\n",
      "Construction     : < newsdoc1.txt , 2 ,[ 356 664 ] >  0 \n",
      "\n",
      "Instructional    : < newsdoc1.txt , 2 ,[ 360 668 ] >  0 \n",
      "\n",
      "Master           : < newsdoc1.txt , 10 ,[ 362 377 386 391 396 670 685 694 699 704 ] >  0 \n",
      "\n",
      "'s               : < newsdoc1.txt , 10 ,[ 363 378 387 392 397 671 686 695 700 705 ] >  0 \n",
      "\n",
      "Bachelors        : < newsdoc1.txt , 2 ,[ 367 675 ] >  0 \n",
      "\n",
      "Degree           : < newsdoc1.txt , 2 ,[ 368 676 ] >  < newsdoc2.txt , 2 ,[ 266 528 ] >  \n",
      "\n",
      "MBA              : < newsdoc1.txt , 2 ,[ 382 690 ] >  0 \n",
      "\n",
      "Electrical       : < newsdoc1.txt , 2 ,[ 389 697 ] >  0 \n",
      "\n",
      "New              : < newsdoc1.txt , 1 ,[ 450 ] >  0 \n",
      "\n",
      "!                : < newsdoc1.txt , 1 ,[ 451 ] >  0 \n",
      "\n",
      "Reinforcement    : < newsdoc1.txt , 1 ,[ 452 ] >  0 \n",
      "\n",
      "Specialization   : < newsdoc1.txt , 1 ,[ 454 ] >  0 \n",
      "\n",
      "Stanford         : 0 < newsdoc2.txt , 26 ,[ 0 35 37 42 59 68 84 115 156 185 213 317 319 324 330 349 365 379 403 434 456 475 582 584 589 595 ] >  \n",
      "\n",
      "Select           : 0 < newsdoc2.txt , 2 ,[ 2 5 ] >  \n",
      "\n",
      "a                : 0 < newsdoc2.txt , 8 ,[ 3 57 66 222 246 363 484 508 ] >  \n",
      "\n",
      "topic            : 0 < newsdoc2.txt , 1 ,[ 4 ] >  \n",
      "\n",
      "one              : 0 < newsdoc2.txt , 1 ,[ 6 ] >  \n",
      "\n",
      "or               : 0 < newsdoc2.txt , 1 ,[ 7 ] >  \n",
      "\n",
      "more             : 0 < newsdoc2.txt , 3 ,[ 8 303 565 ] >  \n",
      "\n",
      "Graduate         : 0 < newsdoc2.txt , 6 ,[ 11 27 75 209 242 504 ] >  \n",
      "\n",
      "Professional     : 0 < newsdoc2.txt , 4 ,[ 13 29 77 211 ] >  \n",
      "\n",
      "Available        : 0 < newsdoc2.txt , 16 ,[ 16 21 23 25 99 106 135 145 171 178 200 207 394 423 449 471 ] >  \n",
      "\n",
      "Open             : 0 < newsdoc2.txt , 16 ,[ 19 93 100 126 132 136 142 165 172 194 201 388 414 420 443 465 ] >  \n",
      "\n",
      "edX              : 0 < newsdoc2.txt , 4 ,[ 20 133 143 421 ] >  \n",
      "\n",
      "Copyright        : 0 < newsdoc2.txt , 3 ,[ 34 337 602 ] >  \n",
      "\n",
      "University       : 0 < newsdoc2.txt , 1 ,[ 36 ] >  \n",
      "\n",
      "California       : 0 < newsdoc2.txt , 2 ,[ 39 43 ] >  \n",
      "\n",
      "94305            : 0 < newsdoc2.txt , 2 ,[ 40 44 ] >  \n",
      "\n",
      "Courses          : 0 < newsdoc2.txt , 3 ,[ 45 351 373 ] >  \n",
      "\n",
      "Schools          : 0 < newsdoc2.txt , 2 ,[ 47 353 ] >  \n",
      "\n",
      "&                : 0 < newsdoc2.txt , 4 ,[ 48 327 354 592 ] >  \n",
      "\n",
      "Us               : 0 < newsdoc2.txt , 2 ,[ 51 357 ] >  \n",
      "\n",
      "Overview         : 0 < newsdoc2.txt , 3 ,[ 52 61 358 ] >  \n",
      "\n",
      "Lifetime         : 0 < newsdoc2.txt , 3 ,[ 58 67 364 ] >  \n",
      "\n",
      "Credentials      : 0 < newsdoc2.txt , 3 ,[ 60 69 366 ] >  \n",
      "\n",
      "Get              : 0 < newsdoc2.txt , 2 ,[ 70 367 ] >  \n",
      "\n",
      "Info             : 0 < newsdoc2.txt , 4 ,[ 72 332 369 597 ] >  \n",
      "\n",
      "Work             : 0 < newsdoc2.txt , 2 ,[ 79 374 ] >  \n",
      "\n",
      "Smarter          : 0 < newsdoc2.txt , 2 ,[ 80 375 ] >  \n",
      "\n",
      "Crowdsourcing    : 0 < newsdoc2.txt , 2 ,[ 82 377 ] >  \n",
      "\n",
      "XDGT211          : 0 < newsdoc2.txt , 2 ,[ 83 378 ] >  \n",
      "\n",
      "School           : 0 < newsdoc2.txt , 8 ,[ 85 116 157 186 380 404 435 457 ] >  \n",
      "\n",
      "When             : 0 < newsdoc2.txt , 8 ,[ 88 121 160 189 383 409 438 460 ] >  \n",
      "\n",
      "/                : 0 < newsdoc2.txt , 16 ,[ 89 91 122 124 161 163 190 192 384 386 410 412 439 441 461 463 ] >  \n",
      "\n",
      "Where            : 0 < newsdoc2.txt , 8 ,[ 90 123 162 191 385 411 440 462 ] >  \n",
      "\n",
      "Enrollment       : 0 < newsdoc2.txt , 20 ,[ 92 95 102 125 128 138 164 167 174 193 196 203 387 390 413 416 442 445 464 467 ] >  \n",
      "\n",
      "-                : 0 < newsdoc2.txt , 12 ,[ 98 105 134 144 170 177 199 206 393 422 448 470 ] >  \n",
      "\n",
      "Defining         : 0 < newsdoc2.txt , 2 ,[ 107 395 ] >  \n",
      "\n",
      "String           : 0 < newsdoc2.txt , 2 ,[ 109 397 ] >  \n",
      "\n",
      "Quartet          : 0 < newsdoc2.txt , 2 ,[ 110 398 ] >  \n",
      "\n",
      "II               : 0 < newsdoc2.txt , 2 ,[ 111 399 ] >  \n",
      "\n",
      "Beethoven        : 0 < newsdoc2.txt , 2 ,[ 113 401 ] >  \n",
      "\n",
      "SOHS-YMUSIC0004  : 0 < newsdoc2.txt , 2 ,[ 114 402 ] >  \n",
      "\n",
      "Cryptocurrency   : 0 < newsdoc2.txt , 2 ,[ 148 426 ] >  \n",
      "\n",
      "What             : 0 < newsdoc2.txt , 2 ,[ 150 428 ] >  \n",
      "\n",
      "You              : 0 < newsdoc2.txt , 2 ,[ 151 429 ] >  \n",
      "\n",
      "Need             : 0 < newsdoc2.txt , 2 ,[ 152 430 ] >  \n",
      "\n",
      "Know             : 0 < newsdoc2.txt , 2 ,[ 154 432 ] >  \n",
      "\n",
      "SOE-XCS0001      : 0 < newsdoc2.txt , 2 ,[ 155 433 ] >  \n",
      "\n",
      "Strategies       : 0 < newsdoc2.txt , 4 ,[ 179 292 450 554 ] >  \n",
      "\n",
      "Debriefing       : 0 < newsdoc2.txt , 2 ,[ 181 452 ] >  \n",
      "\n",
      "Healthcare       : 0 < newsdoc2.txt , 2 ,[ 182 453 ] >  \n",
      "\n",
      "Scenarios        : 0 < newsdoc2.txt , 2 ,[ 183 454 ] >  \n",
      "\n",
      "SOM-XCAPE110     : 0 < newsdoc2.txt , 2 ,[ 184 455 ] >  \n",
      "\n",
      "Medicine         : 0 < newsdoc2.txt , 2 ,[ 188 459 ] >  \n",
      "\n",
      "Transformation   : 0 < newsdoc2.txt , 2 ,[ 215 477 ] >  \n",
      "\n",
      "Certificate      : 0 < newsdoc2.txt , 4 ,[ 216 243 478 505 ] >  \n",
      "\n",
      "We               : 0 < newsdoc2.txt , 2 ,[ 217 479 ] >  \n",
      "\n",
      "’                : 0 < newsdoc2.txt , 2 ,[ 218 480 ] >  \n",
      "\n",
      "re               : 0 < newsdoc2.txt , 2 ,[ 219 481 ] >  \n",
      "\n",
      "living           : 0 < newsdoc2.txt , 2 ,[ 220 482 ] >  \n",
      "\n",
      "time             : 0 < newsdoc2.txt , 2 ,[ 223 485 ] >  \n",
      "\n",
      "unprecedented    : 0 < newsdoc2.txt , 2 ,[ 225 487 ] >  \n",
      "\n",
      "change           : 0 < newsdoc2.txt , 2 ,[ 226 488 ] >  \n",
      "\n",
      "technologies     : 0 < newsdoc2.txt , 2 ,[ 229 491 ] >  \n",
      "\n",
      "are              : 0 < newsdoc2.txt , 4 ,[ 230 307 492 569 ] >  \n",
      "\n",
      "continuously     : 0 < newsdoc2.txt , 2 ,[ 231 493 ] >  \n",
      "\n",
      "disrupting       : 0 < newsdoc2.txt , 2 ,[ 232 494 ] >  \n",
      "\n",
      "marketplace      : 0 < newsdoc2.txt , 2 ,[ 234 496 ] >  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forcing          : 0 < newsdoc2.txt , 2 ,[ 236 498 ] >  \n",
      "\n",
      "companies        : 0 < newsdoc2.txt , 2 ,[ 237 499 ] >  \n",
      "\n",
      "to…              : 0 < newsdoc2.txt , 2 ,[ 238 500 ] >  \n",
      "\n",
      "Entrepreneurship  : 0 < newsdoc2.txt , 4 ,[ 241 244 503 506 ] >  \n",
      "\n",
      "is               : 0 < newsdoc2.txt , 4 ,[ 245 278 507 540 ] >  \n",
      "\n",
      "challenging      : 0 < newsdoc2.txt , 2 ,[ 247 509 ] >  \n",
      "\n",
      "rewarding        : 0 < newsdoc2.txt , 2 ,[ 249 511 ] >  \n",
      "\n",
      "endeavor         : 0 < newsdoc2.txt , 2 ,[ 250 512 ] >  \n",
      "\n",
      "rooted           : 0 < newsdoc2.txt , 2 ,[ 251 513 ] >  \n",
      "\n",
      "creativity       : 0 < newsdoc2.txt , 2 ,[ 253 515 ] >  \n",
      "\n",
      "realized         : 0 < newsdoc2.txt , 2 ,[ 255 517 ] >  \n",
      "\n",
      "through          : 0 < newsdoc2.txt , 2 ,[ 256 518 ] >  \n",
      "\n",
      "practical        : 0 < newsdoc2.txt , 2 ,[ 257 519 ] >  \n",
      "\n",
      "decisions        : 0 < newsdoc2.txt , 2 ,[ 258 520 ] >  \n",
      "\n",
      "strategies       : 0 < newsdoc2.txt , 2 ,[ 260 522 ] >  \n",
      "\n",
      "This…            : 0 < newsdoc2.txt , 2 ,[ 262 524 ] >  \n",
      "\n",
      "Chemical         : 0 < newsdoc2.txt , 2 ,[ 263 525 ] >  \n",
      "\n",
      "MS               : 0 < newsdoc2.txt , 2 ,[ 265 527 ] >  \n",
      "\n",
      "Life             : 0 < newsdoc2.txt , 2 ,[ 267 529 ] >  \n",
      "\n",
      "Energy           : 0 < newsdoc2.txt , 2 ,[ 269 531 ] >  \n",
      "\n",
      "Environment      : 0 < newsdoc2.txt , 2 ,[ 271 533 ] >  \n",
      "\n",
      "This             : 0 < newsdoc2.txt , 2 ,[ 273 535 ] >  \n",
      "\n",
      "triad            : 0 < newsdoc2.txt , 2 ,[ 274 536 ] >  \n",
      "\n",
      "engineering      : 0 < newsdoc2.txt , 2 ,[ 276 538 ] >  \n",
      "\n",
      "priorities       : 0 < newsdoc2.txt , 2 ,[ 277 539 ] >  \n",
      "\n",
      "perhaps          : 0 < newsdoc2.txt , 2 ,[ 279 541 ] >  \n",
      "\n",
      "unmatched        : 0 < newsdoc2.txt , 2 ,[ 280 542 ] >  \n",
      "\n",
      "its              : 0 < newsdoc2.txt , 2 ,[ 282 544 ] >  \n",
      "\n",
      "potential        : 0 < newsdoc2.txt , 2 ,[ 283 545 ] >  \n",
      "\n",
      "improving        : 0 < newsdoc2.txt , 2 ,[ 285 547 ] >  \n",
      "\n",
      "quality          : 0 < newsdoc2.txt , 2 ,[ 287 549 ] >  \n",
      "\n",
      "life             : 0 < newsdoc2.txt , 2 ,[ 289 551 ] >  \n",
      "\n",
      "all…             : 0 < newsdoc2.txt , 2 ,[ 291 553 ] >  \n",
      "\n",
      "Sustainability   : 0 < newsdoc2.txt , 2 ,[ 294 556 ] >  \n",
      "\n",
      "Program          : 0 < newsdoc2.txt , 2 ,[ 295 557 ] >  \n",
      "\n",
      "As               : 0 < newsdoc2.txt , 2 ,[ 296 558 ] >  \n",
      "\n",
      "employees        : 0 < newsdoc2.txt , 2 ,[ 297 559 ] >  \n",
      "\n",
      "customers        : 0 < newsdoc2.txt , 2 ,[ 299 561 ] >  \n",
      "\n",
      "communities      : 0 < newsdoc2.txt , 2 ,[ 301 563 ] >  \n",
      "\n",
      "demand           : 0 < newsdoc2.txt , 2 ,[ 302 564 ] >  \n",
      "\n",
      "transparency     : 0 < newsdoc2.txt , 2 ,[ 304 566 ] >  \n",
      "\n",
      "organizations    : 0 < newsdoc2.txt , 2 ,[ 306 568 ] >  \n",
      "\n",
      "increasingly     : 0 < newsdoc2.txt , 2 ,[ 308 570 ] >  \n",
      "\n",
      "being            : 0 < newsdoc2.txt , 2 ,[ 309 571 ] >  \n",
      "\n",
      "evaluated        : 0 < newsdoc2.txt , 2 ,[ 310 572 ] >  \n",
      "\n",
      "impact           : 0 < newsdoc2.txt , 2 ,[ 313 575 ] >  \n",
      "\n",
      "they             : 0 < newsdoc2.txt , 2 ,[ 314 576 ] >  \n",
      "\n",
      "have             : 0 < newsdoc2.txt , 2 ,[ 315 577 ] >  \n",
      "\n",
      "on…              : 0 < newsdoc2.txt , 2 ,[ 316 578 ] >  \n",
      "\n",
      "VPTL             : 0 < newsdoc2.txt , 2 ,[ 320 585 ] >  \n",
      "\n",
      "Home             : 0 < newsdoc2.txt , 2 ,[ 325 590 ] >  \n",
      "\n",
      "Maps             : 0 < newsdoc2.txt , 2 ,[ 326 591 ] >  \n",
      "\n",
      "Directions       : 0 < newsdoc2.txt , 2 ,[ 328 593 ] >  \n",
      "\n",
      "Emergency        : 0 < newsdoc2.txt , 2 ,[ 331 596 ] >  \n",
      "\n",
      "Use              : 0 < newsdoc2.txt , 2 ,[ 335 600 ] >  \n",
      "\n",
      "Trademarks       : 0 < newsdoc2.txt , 2 ,[ 338 603 ] >  \n",
      "\n",
      "Non-Discrimination  : 0 < newsdoc2.txt , 2 ,[ 339 604 ] >  \n",
      "\n",
      "Skip             : 0 < newsdoc2.txt , 2 ,[ 341 345 ] >  \n",
      "\n",
      "main             : 0 < newsdoc2.txt , 2 ,[ 343 347 ] >  \n",
      "\n",
      "navigation       : 0 < newsdoc2.txt , 1 ,[ 344 ] >  \n",
      "\n",
      "content          : 0 < newsdoc2.txt , 1 ,[ 348 ] >  \n",
      "\n",
      "/about-us/learning-for-a-lifetime  : 0 < newsdoc2.txt , 1 ,[ 579 ] >  \n",
      "\n",
      "/about-us/stanford-credentials  : 0 < newsdoc2.txt , 1 ,[ 580 ] >  \n",
      "\n",
      "/about-us/community  : 0 < newsdoc2.txt , 1 ,[ 581 ] >  \n",
      "\n",
      "number of words in this site is:329\n"
     ]
    }
   ],
   "source": [
    "filenames=[\"newsdoc1.txt\",\"newsdoc2.txt\"]\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import nltk\n",
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "v=[]\n",
    "\n",
    "def retrieve_page(url): \n",
    "    sauce=urllib.request.urlopen(url).read()\n",
    "    soup=bs.BeautifulSoup(sauce,'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_text(page):\n",
    "    word=[]\n",
    "    text_p = (''.join(s.findAll(text=True))for s in page.findAll('p'))\n",
    "    c_p = Counter((x.rstrip(punctuation).lower() for y in text_p for x in y.split()))\n",
    "\n",
    "    # We get the words within divs\n",
    "    text_div = (''.join(s.findAll(text=True))for s in page.findAll('div'))\n",
    "    c_div = Counter((x.rstrip(punctuation).lower() for y in text_div for x in y.split()))\n",
    "\n",
    "    for w in text_div:\n",
    "        word.append(w)\n",
    "\n",
    "    for w in text_p:\n",
    "        word.append(w)\n",
    "    \n",
    "    for span in page.find_all('span'):\n",
    "        word.append(span.text)\n",
    "    for li in page.find_all('li'):\n",
    "        word.append(li.text)\n",
    "    for url in page.find_all('a'):\n",
    "        word.append(url.text)\n",
    "        \n",
    "    return word\n",
    "\n",
    "def writing(word,doc):\n",
    "    f=open(doc,'w')\n",
    "    for words in word:\n",
    "        f.write(words+'\\n')\n",
    "    f.close()\n",
    "    \n",
    "def tokenize():\n",
    "    symb=[\"/\",\",\",\">\",\"<\",\"!\",\"``\",\"~\",\":\",\";\",\"/\"\"/\",\"/''/\",\"&\",\"}\",\"{\",\"[\",\"]\",\"(\",\")\"]\n",
    "    j=1\n",
    "    temp=[]\n",
    "    paragraph=[]\n",
    "    for filename in filenames:\n",
    "        f=open(filename,\"r\").read()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(f)\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                if w not in symb: \n",
    "                    filtered_sentence.append(w)\n",
    "        j+=1\n",
    "        for word in word_tokens:\n",
    "            if word not in paragraph:\n",
    "                paragraph.append(word)\n",
    "        print('\\n\\n\\n')\n",
    "        print(\"words\\t\\t Doc1 Doc2\\n\")\n",
    "        k=0\n",
    "        for word in paragraph:\n",
    "            print(word,\" \"*(15-len(word)),': ',end='')\n",
    "            for filename in filenames:\n",
    "                k=0\n",
    "                f=open(filename,\"r\").read()\n",
    "                word_tokens=word_tokenize(f)\n",
    "                v=Counter(word_tokens)\n",
    "                for word1 in word_tokens:\n",
    "                    if word1 not in temp:\n",
    "                        temp.append(word1)\n",
    "                    \n",
    "                for word1 in temp:\n",
    "                    if word==word1:\n",
    "                        if(v[word]>0):\n",
    "                            a=0\n",
    "                            print('<',filename,',',v[word],',[',end=' ')\n",
    "                            for w in word_tokens:\n",
    "                                if w==word:\n",
    "                                    print(a,'',end='')\n",
    "                                a=a+1    \n",
    "                            print('] >',' ',end='')\n",
    "                        else:\n",
    "                            print('0','',end='')\n",
    "                        k=1\n",
    "                if(k!=1):\n",
    "                    print(0,'',end='')\n",
    "            print(\"\\n\")\n",
    "        print(\"number of words in this site is:\"+\"\",end=\"\")\n",
    "        print(len(paragraph))\n",
    "    return(temp)\n",
    "\n",
    "#coursera\n",
    "url1='https://www.coursera.org'\n",
    "page1=retrieve_page(url1)\n",
    "word1=get_text(page1)\n",
    "writing(word1,filenames[0])\n",
    "\n",
    "#khanacademy\n",
    "url2='https://online.stanford.edu/'\n",
    "page2=retrieve_page(url2)\n",
    "word2=get_text(page2)\n",
    "writing(word2,filenames[1])\n",
    "\n",
    "result_11=tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
